{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eff128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models,losses,regularizers,constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06835b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,810\n",
      "Trainable params: 4,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, input_dim = 64, kernel_regularizer = regularizers.l1_l2(0.01,0.01),\n",
    "                      #kernel_regularizer = regularizers.l2(0.01),\n",
    "                      #activity_regularizer = regularizers.l1(0.01),\n",
    "                      kernel_constraint = constraints.MaxNorm(max_value = 2, axis = 0)))\n",
    "\n",
    "model.add(layers.Dense(10,\n",
    "                      kernel_regularizer = regularizers.l1_l2(0.01,0.01),activation = 'sigmoid' ))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'sparse_categorical_crossentropy', metrics = ['AUC'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166f232",
   "metadata": {},
   "source": [
    "对于keras模型，目标函数中的正则化项一般在各层中指定，例如使用Dense的 kernel_regularizer 和 bias_regularizer等参数指定权重使用l1或者l2正则化项，此外还可以用kernel_constraint 和 bias_constraint等参数约束权重的取值范围，这也是一种正则化手段。\n",
    "\n",
    "回归模型，loss function通常为 mean_squared_error。\n",
    "\n",
    "二分类模型，loss function通常为 binary_crossentropy。\n",
    "\n",
    "对于多分类模型，如果label是one-hot编码的，则使用交叉熵损失函数 categorical_crossentropy。\n",
    "             如果label是序号编码的，则需要使用稀疏类别交叉熵损失函数 sparse_categorical_crossentropy。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068cb4cb",
   "metadata": {},
   "source": [
    "常用的一些内置损失函数说明如下。\n",
    "\n",
    "mean_squared_error（平方差误差损失，用于回归，简写为 mse, 类实现形式为 MeanSquaredError 和 MSE）\n",
    "\n",
    "mean_absolute_error (绝对值误差损失，用于回归，简写为 mae, 类实现形式为 MeanAbsoluteError 和 MAE)\n",
    "\n",
    "mean_absolute_percentage_error (平均百分比误差损失，用于回归，简写为 mape, 类实现形式为 MeanAbsolutePercentageError 和 MAPE)\n",
    "\n",
    "Huber(Huber损失，只有类实现形式，用于回归，介于mse和mae之间，对异常值比较鲁棒，相对mse有一定的优势)\n",
    "\n",
    "binary_crossentropy(二元交叉熵，用于二分类，类实现形式为 BinaryCrossentropy)\n",
    "\n",
    "categorical_crossentropy(类别交叉熵，用于多分类，要求label为onehot编码，类实现形式为 CategoricalCrossentropy)\n",
    "\n",
    "sparse_categorical_crossentropy(稀疏类别交叉熵，用于多分类，要求label为序号编码形式，类实现形式为 SparseCategoricalCrossentropy)\n",
    "\n",
    "hinge(合页损失函数，用于二分类，最著名的应用是作为支持向量机SVM的损失函数，类实现形式为 Hinge)\n",
    "\n",
    "kld(相对熵损失，也叫KL散度，常用于最大期望算法EM的损失函数，两个概率分布差异的一种信息度量。类实现形式为 KLDivergence 或 KLD)\n",
    "\n",
    "cosine_similarity(余弦相似度，可用于多分类，类实现形式为 CosineSimilarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33555e88",
   "metadata": {},
   "source": [
    "# 评估指标Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d03ab",
   "metadata": {},
   "source": [
    "MeanSquaredError（平方差误差，用于回归，可以简写为MSE，函数形式为mse）\n",
    "\n",
    "MeanAbsoluteError (绝对值误差，用于回归，可以简写为MAE，函数形式为mae)\n",
    "\n",
    "MeanAbsolutePercentageError (平均百分比误差，用于回归，可以简写为MAPE，函数形式为mape)\n",
    "\n",
    "RootMeanSquaredError (均方根误差，用于回归)\n",
    "\n",
    "Accuracy (准确率，用于分类，可以用字符串\"Accuracy\"表示，Accuracy=(TP+TN)/(TP+TN+FP+FN)，要求y_true和y_pred都为类别序号编码)\n",
    "\n",
    "Precision (精确率，用于二分类，Precision = TP/(TP+FP))\n",
    "\n",
    "Recall (召回率，用于二分类，Recall = TP/(TP+FN))\n",
    "\n",
    "TruePositives (真正例，用于二分类)\n",
    "\n",
    "TrueNegatives (真负例，用于二分类)\n",
    "\n",
    "FalsePositives (假正例，用于二分类)\n",
    "\n",
    "FalseNegatives (假负例，用于二分类)\n",
    "\n",
    "AUC(ROC曲线(TPR vs FPR)下的面积，用于二分类，直观解释为随机抽取一个正样本和一个负样本，正样本的预测值大于负样本的概率)\n",
    "\n",
    "CategoricalAccuracy（分类准确率，与Accuracy含义相同，要求y_true(label)为onehot编码形式）\n",
    "\n",
    "SparseCategoricalAccuracy (稀疏分类准确率，与Accuracy含义相同，要求y_true(label)为序号编码形式)\n",
    "\n",
    "MeanIoU (Intersection-Over-Union，常用于图像分割)\n",
    "\n",
    "TopKCategoricalAccuracy (多分类TopK准确率，要求y_true(label)为onehot编码形式)\n",
    "\n",
    "SparseTopKCategoricalAccuracy (稀疏多分类TopK准确率，要求y_true(label)为序号编码形式)\n",
    "\n",
    "Mean (平均值)\n",
    "\n",
    "Sum (求和)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f1f38",
   "metadata": {},
   "source": [
    "# 优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01ba5e",
   "metadata": {},
   "source": [
    "深度学习优化算法大概经历了 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam 这样的发展历程。\n",
    "\n",
    "对于一般新手炼丹师，优化器直接使用Adam，并使用其默认参数就OK了。\n",
    "\n",
    "一些爱写论文的炼丹师由于追求评估指标效果，可能会偏爱前期使用Adam优化器快速下降，后期使用SGD并精调优化器参数得到更好的结果。\n",
    "\n",
    "此外目前也有一些前沿的优化算法，据称效果比Adam更好，例如LazyAdam, Look-ahead, RAdam, Ranger等."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8fa74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印时间分割线\n",
    "@tf.function\n",
    "def printbar():\n",
    "    ts = tf.timestamp()\n",
    "    today_ts = ts%(24*60*60)\n",
    "\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "    \n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return(tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\",m))\n",
    "    \n",
    "    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n",
    "                timeformat(second)],separator = \":\")\n",
    "    tf.print(\"==========\"*8,end = \"\")\n",
    "    tf.print(timestring)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2391568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================14:18:54\n",
      "step ==  100\n",
      "x == 0.867380381\n",
      "\n",
      "================================================================================14:18:54\n",
      "step ==  200\n",
      "x == 0.98241204\n",
      "\n",
      "================================================================================14:18:54\n",
      "step ==  300\n",
      "x == 0.997667611\n",
      "\n",
      "================================================================================14:18:54\n",
      "step ==  400\n",
      "x == 0.999690711\n",
      "\n",
      "================================================================================14:18:54\n",
      "step ==  500\n",
      "x == 0.999959\n",
      "\n",
      "================================================================================14:18:54\n",
      "step ==  600\n",
      "x == 0.999994516\n",
      "\n",
      "y = 0\n",
      "x = 0.999995232\n"
     ]
    }
   ],
   "source": [
    "# 求f(x) = a*x**2 + b*x + c的最小值\n",
    "\n",
    "# 使用optimizer.apply_gradients\n",
    "\n",
    "x = tf.Variable(0.0, name = 'x', dtype = tf.float32)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01)\n",
    "\n",
    "@tf.function\n",
    "def minimizef():\n",
    "    a = tf.constant(1.0)\n",
    "    b = tf.constant(-2.0)\n",
    "    c = tf.constant(1.0)\n",
    "    \n",
    "    while tf.constant(True):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y = a*tf.pow(x,2) + b*x +c\n",
    "        dy_dx = tape.gradient(y,x)\n",
    "        optimizer.apply_gradients(grads_and_vars = [(dy_dx,x)])\n",
    "        \n",
    "        #迭代终止条件\n",
    "        if tf.abs(dy_dx) < tf.constant(0.00001):\n",
    "            break\n",
    "        \n",
    "        if tf.math.mod(optimizer.iterations, 100) ==0:\n",
    "            printbar()\n",
    "            tf.print('step == ',optimizer.iterations)\n",
    "            tf.print('x ==', x)\n",
    "            tf.print('')\n",
    "            \n",
    "    y = a*tf.pow(x,2) + b*x + c\n",
    "    return y\n",
    "\n",
    "tf.print('y =', minimizef())\n",
    "tf.print('x =', x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c87eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1000\n",
      "y =  0\n",
      "x =  0.999998569\n"
     ]
    }
   ],
   "source": [
    "# 求f(x) = a*x**2 + b*x + c的最小值\n",
    "\n",
    "# 使用optimizer.minimize\n",
    "\n",
    "x = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)   \n",
    "\n",
    "def f():   \n",
    "    a = tf.constant(1.0)\n",
    "    b = tf.constant(-2.0)\n",
    "    c = tf.constant(1.0)\n",
    "    y = a*tf.pow(x,2)+b*x+c\n",
    "    return(y)\n",
    "\n",
    "@tf.function\n",
    "def train(epoch):  \n",
    "    for _ in tf.range(epoch):  \n",
    "        optimizer.minimize(f,[x])\n",
    "    tf.print(\"epoch = \",optimizer.iterations)\n",
    "    return(f())\n",
    "\n",
    "train(1000)\n",
    "tf.print(\"y = \",f())\n",
    "tf.print(\"x = \",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7e71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
